{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24984ad",
   "metadata": {},
   "source": [
    "# Get data from data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b27c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'sparklyr'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#I use librart sparklyr to connect and get data from Hadoop\n",
    "library(sparklyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "050f94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark <- spark_connect(master='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25072f55",
   "metadata": {},
   "source": [
    "In this code I allow the user to get a sample of data by month.\n",
    "  + Month starts\n",
    "  + Month ends\n",
    "  \n",
    "Depending on the date you crawl data in part1 how much data you will be able to get from datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52c91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter month start:6\n",
      "Enter month end:7\n",
      "[1] \"hdfs://localhost:9000/datalake/2023/06/output_weather_in_*\"\n",
      "[1] \"06\"\n",
      "[1] \"hdfs://localhost:9000/datalake/2023/07/output_weather_in_*\"\n",
      "[1] \"07\"\n"
     ]
    }
   ],
   "source": [
    "month_start=as.integer(readline('Enter month start:'))\n",
    "month_end=as.integer(readline('Enter month end:'))\n",
    "df <- data.frame()\n",
    "for (month in (month_start:month_end)){\n",
    "    month<-sprintf(\"%02d\", month)\n",
    "    path=paste0(\"hdfs://localhost:9000/datalake/2023/\",month,\"/output_weather_in_*\")\n",
    "    print(path)\n",
    "    if (month==sprintf(\"%02d\",month_start)){\n",
    "        df <- spark_read_parquet(spark,path=path)\n",
    "        df <-df %>% mutate(Date=as.POSIXct(Date))\n",
    "        df <- df %>% collect()\n",
    "    }\n",
    "    else{\n",
    "        read <- spark_read_parquet(spark,path=path)\n",
    "        read <-read %>% mutate(Date=as.POSIXct(Date))\n",
    "        read <- read %>% collect()\n",
    "        df <- rbind(df,read)\n",
    "    }\n",
    "    print(month)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf560e",
   "metadata": {},
   "source": [
    "I will try 2 months demo is 6 and 7\n",
    "\n",
    "The default year here is 2023, I can completely tweak the date, but since this project is done in 2023 I will default it like that\n",
    "- Path: \"hdfs://localhost:9000/datalake/2023/\",month,\"/output_weather_in_*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed3cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will rearrange by month to facilitate analysis and processing time seriese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777d4a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in arrange(df, Date): could not find function \"arrange\"\n",
     "output_type": "error",
     "traceback": [
      "Error in arrange(df, Date): could not find function \"arrange\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "df <- arrange(df, Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(df,'ouput_process.csv', row.names=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aadde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8012b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
